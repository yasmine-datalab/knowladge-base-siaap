[2024-04-22T19:34:02.287+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: pipeline_eq.gen_dates scheduled__2024-03-07T00:00:00+00:00 [queued]>
[2024-04-22T19:34:02.294+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: pipeline_eq.gen_dates scheduled__2024-03-07T00:00:00+00:00 [queued]>
[2024-04-22T19:34:02.294+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-04-22T19:34:02.308+0000] {taskinstance.py:2217} INFO - Executing <Task(_PythonDecoratedOperator): gen_dates> on 2024-03-07 00:00:00+00:00
[2024-04-22T19:34:02.314+0000] {standard_task_runner.py:60} INFO - Started process 303846 to run task
[2024-04-22T19:34:02.316+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'pipeline_eq', 'gen_dates', 'scheduled__2024-03-07T00:00:00+00:00', '--job-id', '190', '--raw', '--subdir', 'DAGS_FOLDER/kbs/custom_dags/pipeline_eq.py', '--cfg-path', '/tmp/tmphie8uluo']
[2024-04-22T19:34:02.316+0000] {standard_task_runner.py:88} INFO - Job 190: Subtask gen_dates
[2024-04-22T19:34:02.343+0000] {task_command.py:423} INFO - Running <TaskInstance: pipeline_eq.gen_dates scheduled__2024-03-07T00:00:00+00:00 [running]> on host datalab-yasmine
[2024-04-22T19:34:02.381+0000] {logging_mixin.py:188} WARNING - /home/yasmine/.local/share/virtualenvs/knowledge-base-siaap-WvBZnYs-/lib/python3.8/site-packages/airflow/utils/context.py:207 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2024-04-22T19:34:02.405+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='pipeline_eq' AIRFLOW_CTX_TASK_ID='gen_dates' AIRFLOW_CTX_EXECUTION_DATE='2024-03-07T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-03-07T00:00:00+00:00'
[2024-04-22T19:34:02.407+0000] {rw.py:83} INFO - Starting to save files into Minio
[2024-04-22T19:34:04.085+0000] {rw.py:87} INFO - intervalles created
[2024-04-22T19:34:04.085+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/yasmine/.local/share/virtualenvs/knowledge-base-siaap-WvBZnYs-/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/yasmine/.local/share/virtualenvs/knowledge-base-siaap-WvBZnYs-/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/yasmine/.local/share/virtualenvs/knowledge-base-siaap-WvBZnYs-/lib/python3.8/site-packages/airflow/decorators/base.py", line 241, in execute
    return_value = super().execute(context)
  File "/home/yasmine/.local/share/virtualenvs/knowledge-base-siaap-WvBZnYs-/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/yasmine/.local/share/virtualenvs/knowledge-base-siaap-WvBZnYs-/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/yasmine/Documents/FREELANCE/knowledge-base-siaap/dags/kbs/custom_dags/pipeline_eq.py", line 48, in gen_dates
    save_files_minio(dates, filename+".json", "intervalles")
  File "/home/yasmine/Documents/FREELANCE/knowledge-base-siaap/dags/kbs/common/rw.py", line 89, in save_files_minio
    serialize_data = json.dumps(data)
  File "/home/yasmine/.pyenv/versions/3.8.16/lib/python3.8/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/home/yasmine/.pyenv/versions/3.8.16/lib/python3.8/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/home/yasmine/.pyenv/versions/3.8.16/lib/python3.8/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/yasmine/.pyenv/versions/3.8.16/lib/python3.8/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type datetime is not JSON serializable
[2024-04-22T19:34:04.089+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=pipeline_eq, task_id=gen_dates, execution_date=20240307T000000, start_date=20240422T193402, end_date=20240422T193404
[2024-04-22T19:34:04.100+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 190 for task gen_dates (Object of type datetime is not JSON serializable; 303846)
[2024-04-22T19:34:04.132+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-04-22T19:34:04.147+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-23T11:20:33.162+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: pipeline_eq.gen_dates scheduled__2024-03-07T00:00:00+00:00 [queued]>
[2024-04-23T11:20:33.167+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: pipeline_eq.gen_dates scheduled__2024-03-07T00:00:00+00:00 [queued]>
[2024-04-23T11:20:33.167+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-04-23T11:20:33.179+0000] {taskinstance.py:2217} INFO - Executing <Task(_PythonDecoratedOperator): gen_dates> on 2024-03-07 00:00:00+00:00
[2024-04-23T11:20:33.185+0000] {standard_task_runner.py:60} INFO - Started process 75162 to run task
[2024-04-23T11:20:33.187+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'pipeline_eq', 'gen_dates', 'scheduled__2024-03-07T00:00:00+00:00', '--job-id', '244', '--raw', '--subdir', 'DAGS_FOLDER/kbs/custom_dags/pipeline_eq.py', '--cfg-path', '/tmp/tmp4y8rhj2o']
[2024-04-23T11:20:33.188+0000] {standard_task_runner.py:88} INFO - Job 244: Subtask gen_dates
[2024-04-23T11:20:33.213+0000] {task_command.py:423} INFO - Running <TaskInstance: pipeline_eq.gen_dates scheduled__2024-03-07T00:00:00+00:00 [running]> on host datalab-yasmine
[2024-04-23T11:20:33.239+0000] {logging_mixin.py:188} WARNING - /home/yasmine/.local/share/virtualenvs/knowledge-base-siaap-WvBZnYs-/lib/python3.8/site-packages/airflow/utils/context.py:207 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2024-04-23T11:20:33.358+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='pipeline_eq' AIRFLOW_CTX_TASK_ID='gen_dates' AIRFLOW_CTX_EXECUTION_DATE='2024-03-07T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-03-07T00:00:00+00:00'
[2024-04-23T11:20:33.358+0000] {rw.py:84} INFO - Starting to save files into Minio
[2024-04-23T11:20:36.710+0000] {connectionpool.py:874} WARNING - Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /intervalles?location=
[2024-04-23T11:20:38.358+0000] {python.py:202} INFO - Done. Returned value was: dates_20240307
[2024-04-23T11:20:38.371+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=pipeline_eq, task_id=gen_dates, execution_date=20240307T000000, start_date=20240423T112033, end_date=20240423T112038
[2024-04-23T11:20:38.405+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-04-23T11:20:38.418+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-04-23T11:24:07.850+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: pipeline_eq.gen_dates scheduled__2024-03-07T00:00:00+00:00 [queued]>
[2024-04-23T11:24:07.855+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: pipeline_eq.gen_dates scheduled__2024-03-07T00:00:00+00:00 [queued]>
[2024-04-23T11:24:07.856+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-04-23T11:24:07.868+0000] {taskinstance.py:2217} INFO - Executing <Task(_PythonDecoratedOperator): gen_dates> on 2024-03-07 00:00:00+00:00
[2024-04-23T11:24:07.872+0000] {standard_task_runner.py:60} INFO - Started process 80479 to run task
[2024-04-23T11:24:07.875+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'pipeline_eq', 'gen_dates', 'scheduled__2024-03-07T00:00:00+00:00', '--job-id', '266', '--raw', '--subdir', 'DAGS_FOLDER/kbs/custom_dags/pipeline_eq.py', '--cfg-path', '/tmp/tmpk4s2whuw']
[2024-04-23T11:24:07.876+0000] {standard_task_runner.py:88} INFO - Job 266: Subtask gen_dates
[2024-04-23T11:24:07.909+0000] {task_command.py:423} INFO - Running <TaskInstance: pipeline_eq.gen_dates scheduled__2024-03-07T00:00:00+00:00 [running]> on host datalab-yasmine
[2024-04-23T11:24:07.938+0000] {logging_mixin.py:188} WARNING - /home/yasmine/.local/share/virtualenvs/knowledge-base-siaap-WvBZnYs-/lib/python3.8/site-packages/airflow/utils/context.py:207 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2024-04-23T11:24:08.061+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='pipeline_eq' AIRFLOW_CTX_TASK_ID='gen_dates' AIRFLOW_CTX_EXECUTION_DATE='2024-03-07T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-03-07T00:00:00+00:00'
[2024-04-23T11:24:08.062+0000] {logging_mixin.py:188} INFO - {'start': '2024-03-07 00:00:00+00:00', 'end': '2024-04-23 11:24:08'}
[2024-04-23T11:24:08.062+0000] {rw.py:84} INFO - Starting to save files into Minio
[2024-04-23T11:24:10.015+0000] {python.py:202} INFO - Done. Returned value was: dates_20240307
[2024-04-23T11:24:10.030+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=pipeline_eq, task_id=gen_dates, execution_date=20240307T000000, start_date=20240423T112407, end_date=20240423T112410
[2024-04-23T11:24:10.058+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-04-23T11:24:10.087+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
